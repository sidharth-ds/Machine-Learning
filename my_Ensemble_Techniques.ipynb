{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_Ensemble Techniques.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03lbhw76NWlL"
      },
      "source": [
        "## **Ensemble Technqiues**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jucpVMWMZrCW"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "TtSHXQ1wZr8W",
        "outputId": "e481a177-4c9d-455e-a798-af9367bfc72b"
      },
      "source": [
        "#importing important packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#reading the dataset\n",
        "df=pd.read_csv(\"train.csv\")\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e763bf49-3aa2-4998-a345-37d9573216b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LP001011</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5417</td>\n",
              "      <td>4196.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>LP002978</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>LP002979</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3+</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>LP002983</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>8072</td>\n",
              "      <td>240.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>LP002984</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>7583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>LP002990</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Semiurban</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>492 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e763bf49-3aa2-4998-a345-37d9573216b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e763bf49-3aa2-4998-a345-37d9573216b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e763bf49-3aa2-4998-a345-37d9573216b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
              "1    LP001003    Male     Yes          1      Graduate            No   \n",
              "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
              "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
              "4    LP001008    Male      No          0      Graduate            No   \n",
              "5    LP001011    Male     Yes          2      Graduate           Yes   \n",
              "..        ...     ...     ...        ...           ...           ...   \n",
              "609  LP002978  Female      No          0      Graduate            No   \n",
              "610  LP002979    Male     Yes         3+      Graduate            No   \n",
              "611  LP002983    Male     Yes          1      Graduate            No   \n",
              "612  LP002984    Male     Yes          2      Graduate            No   \n",
              "613  LP002990  Female      No          0      Graduate           Yes   \n",
              "\n",
              "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
              "1               4583             1508.0       128.0             360.0   \n",
              "2               3000                0.0        66.0             360.0   \n",
              "3               2583             2358.0       120.0             360.0   \n",
              "4               6000                0.0       141.0             360.0   \n",
              "5               5417             4196.0       267.0             360.0   \n",
              "..               ...                ...         ...               ...   \n",
              "609             2900                0.0        71.0             360.0   \n",
              "610             4106                0.0        40.0             180.0   \n",
              "611             8072              240.0       253.0             360.0   \n",
              "612             7583                0.0       187.0             360.0   \n",
              "613             4583                0.0       133.0             360.0   \n",
              "\n",
              "     Credit_History Property_Area Loan_Status  \n",
              "1               1.0         Rural           N  \n",
              "2               1.0         Urban           Y  \n",
              "3               1.0         Urban           Y  \n",
              "4               1.0         Urban           Y  \n",
              "5               1.0         Urban           Y  \n",
              "..              ...           ...         ...  \n",
              "609             1.0         Rural           Y  \n",
              "610             1.0         Rural           Y  \n",
              "611             1.0         Urban           Y  \n",
              "612             1.0         Urban           Y  \n",
              "613             0.0     Semiurban           N  \n",
              "\n",
              "[492 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning:\n",
        "\n",
        "df['Gender'].fillna('Male', inplace=True)  # filling missing values with male (since male is most freq)\n",
        "df = df.dropna()   # dropping the null value rows in rest of the features\n",
        "df"
      ],
      "metadata": {
        "id": "D4PAJiq9oPu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u_qacP7Z1KI"
      },
      "source": [
        "#split dataset into train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "del df['Loan_ID']\n",
        "#Both Label and One-hot encoding is performed\n",
        "dfT = pd.get_dummies(df) #encode the data - one hot encoding is done\n",
        "dfT.columns\n",
        "dfT = dfT.drop(['Gender_Male','Married_No','Education_Graduate','Self_Employed_No'], axis = 1)\n",
        "dfT['Dependents'] = dfT['Dependents_0'] + (2 * dfT['Dependents_1']) + (3 * dfT['Dependents_2']) + (4 * dfT['Dependents_3+']) - 1\n",
        "dfT = dfT.drop(['Dependents_0','Dependents_1','Dependents_2','Dependents_3+'], axis = 1)\n",
        "dfT['Loan_Status'] = dfT['Loan_Status_Y']\n",
        "dfT = dfT.drop(['Loan_Status_Y','Loan_Status_N'], axis = 1)\n",
        "dfT\n",
        "\n",
        "#Split my data\n",
        "x_train, x_test, y_train, y_test = train_test_split(dfT[dfT.columns[:-1]].values, dfT['Loan_Status'].values, test_size=0.25, random_state=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac4vb2y_myQy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwFrtT-Z11y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bdd321-6b47-4f27-f294-44e2f01e84c4"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cb_8C3gaSW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a1b723-c436-4eee-c166-a92a4f49718e"
      },
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((369, 13), (123, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOwEsLjuO8L8"
      },
      "source": [
        "# Max Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGXJUGUCOViz"
      },
      "source": [
        "Alternatively, you can use “VotingClassifier” module in sklearn as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl6DolVOOVwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad61678-8917-4d8e-ec40-6d3c89b5df38"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier # this is the function that ensembles my model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(max_depth = 2,random_state=1)\n",
        "model3 = KNeighborsClassifier(3)\n",
        "\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='hard') # it will stitich all the models together, voting = hard means max voting \n",
        "# we need to give the list of models that we are trying to combine\n",
        "\n",
        "model.fit(x_train,y_train) # to train all of the models\n",
        "preds = model.predict(x_test)\n",
        "model.score(x_test,y_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8130081300813008"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3NYpy2IqyR5"
      },
      "source": [
        "# Weighted Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPEAPfanqymY",
        "outputId": "5222b7ea-b51d-4e59-ec4c-65cf601bf5b1"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(max_depth = 2,random_state=1)\n",
        "model3 = KNeighborsClassifier(3)\n",
        "\n",
        "model = VotingClassifier(weights = [0.4,0.4,0.2], estimators=[('lr', model1), ('dt', model2),('knn',model3)], voting='soft') # it will stitich all the models together, voting = soft means averaging coting\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8211382113821138"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN3oT9oqP-MM"
      },
      "source": [
        "# **Advanced Ensemble techniques**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c3aI7BnQB2T"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JJM-WhyQdzj"
      },
      "source": [
        "# Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4BzLCSRRVCc"
      },
      "source": [
        "Blending is similar to bagging but rather than using a K fold cross validation, we use a single validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3h9X-JDd0vO"
      },
      "source": [
        "# **Bagging** (Bootstrap aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH9evpFKd15S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c13b7a-25e9-437c-e4d3-7a751a36f651"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import tree\n",
        "# weakLearner = tree.DecisionTreeClassifier(max_depth = 1)\n",
        "# weakLearner.fit(x_train, y_train)\n",
        "# weakLearner.score(x_test,y_test)\n",
        "model = BaggingClassifier(tree.DecisionTreeClassifier(max_depth = 1, random_state=1), n_estimators=100)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8211382113821138"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n7miqMvhIA9"
      },
      "source": [
        "# **Random Forests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFbqvDeyhHgT",
        "outputId": "015a975b-c1aa-427f-9372-b90c3816a046"
      },
      "source": [
        "# Pandas is used for data manipulation\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "# Read in data as pandas dataframe and display first 5 rows\n",
        "original_features = pd.read_csv('temps.csv') #\n",
        "print(original_features.columns)\n",
        "original_features\n",
        "\n",
        "# Data cleaning\n",
        "# EDA\n",
        "# # Data Encoding\n",
        "# # Data Splitting\n",
        "# # Data scaling\n",
        "# # (if reqd) data transformation\n",
        "\n",
        "original_features.week = original_features.week.map({'Sun':1,'Mon':2,'Tues':3,'Wed':4,'Thurs':5,'Fri':6,'Sat':7})\n",
        "# # # original_features\n",
        "# # # Use numpy to convert to arrays\n",
        "# import numpy as np\n",
        "\n",
        "# # Labels are the values we want to predict\n",
        "original_labels = np.array(original_features['actual']) # target varaibles\n",
        "\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "original_features= original_features.drop('friend', axis = 1)\n",
        "original_features= original_features.drop('actual', axis = 1) #original features\n",
        "\n",
        "# Saving feature names for later use\n",
        "original_feature_list = list(original_features.columns) #orginal feature labels\n",
        "\n",
        "# Convert to numpy array\n",
        "original_features = np.array(original_features) \n",
        "original_features\n",
        "\n",
        "# Using Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "original_train_features, original_test_features, original_train_labels, original_test_labels = train_test_split(original_features, original_labels, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# # The baseline predictions are the historical averages\n",
        "# baseline_preds = original_test_features[:, original_feature_list.index('average')]\n",
        "\n",
        "# # Baseline errors, and display average baseline error\n",
        "# baseline_errors = abs(baseline_preds - original_test_labels)\n",
        "# print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['year', 'month', 'day', 'week', 'temp_2', 'temp_1', 'average', 'actual',\n",
            "       'friend'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qHTDK0Uy9Al",
        "outputId": "90986d9d-a7f2-46bc-aa85-388ca82d127e"
      },
      "source": [
        "original_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(348, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik6scJWniP-z",
        "outputId": "6758a299-f64e-49ac-92e8-03db0cff32ba"
      },
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Instantiate model \n",
        "rf = RandomForestRegressor(n_estimators= 100, max_depth = 3, max_features='sqrt')\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(original_train_features, original_train_labels);\n",
        "\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(original_test_features)\n",
        "\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - original_test_labels)\n",
        "\n",
        "# Print out the mean absolute error (mae)\n",
        "print('MAE :', round(np.mean(errors), 2), 'degrees.')\n",
        "\n",
        "# Compare to baseline\n",
        "# improvement_baseline = 100 * abs(np.mean(errors) - np.mean(baseline_errors)) / np.mean(baseline_errors)\n",
        "# print('Improvement over baseline:', round(improvement_baseline, 2), '%.')\n",
        "\n",
        "#r2_score(baseline_preds, original_test_labels)\n",
        "r2_score(predictions, original_test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE : 4.03 degrees.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6584841101067023"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STuw7_N80zYB",
        "outputId": "c854ecf7-7dea-4e52-b514-58afc8af7eb0"
      },
      "source": [
        "original_train_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(261, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8PXQ0rZhsYd"
      },
      "source": [
        "rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5nL5MSBimst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a65e1a-ad10-43fd-e10d-8adfe36bc2db"
      },
      "source": [
        "original_feature_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['year', 'month', 'day', 'week', 'temp_2', 'temp_1', 'average']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV4HSU4WiaUQ"
      },
      "source": [
        "# Interpret Model Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWAiLsut2MY3"
      },
      "source": [
        "from sklearn import tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6vkYkK3icNP"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import pydot\n",
        "\n",
        "# Pull out one tree from the forest\n",
        "tree = rf.estimators_[5]\n",
        "\n",
        "# Export the image to a dot file\n",
        "export_graphviz(tree, out_file = 'tree.dot', feature_names = original_feature_list, rounded = True, precision = 1)\n",
        "\n",
        "# Use dot file to create a graph\n",
        "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
        "\n",
        "# Write graph to a png file\n",
        "graph.write_png('tree.png');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60tIEyPXi5IT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b052e6-db26-47a8-a190-e1a9049938ed"
      },
      "source": [
        "print('The depth of this tree is:', tree.tree_.max_depth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The depth of this tree is: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3wF-cTi7qt"
      },
      "source": [
        "# Limit depth of tree to 2 levels\n",
        "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\n",
        "rf_small.fit(original_train_features, original_train_labels)\n",
        "\n",
        "# Extract the small tree\n",
        "tree_small = rf_small.estimators_[5]\n",
        "\n",
        "# Save the tree as a png image\n",
        "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = original_feature_list, rounded = True, precision = 1)\n",
        "\n",
        "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
        "\n",
        "graph.write_png('small_tree.png');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhUtbce0jnO3"
      },
      "source": [
        "# Variable Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdbdpAXkjqHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d5c813-fd34-4806-d352-399f48c43118"
      },
      "source": [
        "\n",
        "# Get numerical feature importances\n",
        "importances = list(rf.feature_importances_)\n",
        "\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(original_feature_list, importances)]\n",
        "\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "# Print out the feature and importances \n",
        "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: temp_1               Importance: 0.35\n",
            "Variable: average              Importance: 0.3\n",
            "Variable: temp_2               Importance: 0.24\n",
            "Variable: month                Importance: 0.11\n",
            "Variable: day                  Importance: 0.01\n",
            "Variable: year                 Importance: 0.0\n",
            "Variable: week                 Importance: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRoxVJqDj6gC"
      },
      "source": [
        "# Model with the 2 most important feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DbrjWloj-yW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee9d9fb-ae83-4bc9-d3af-b3096a8c410e"
      },
      "source": [
        "\n",
        "# New random forest with only the two most important variables\n",
        "rf_most_important = RandomForestRegressor(n_estimators= 100, max_depth = 2, max_features='auto')\n",
        "\n",
        "# Extract the two most important features\n",
        "important_indices = [original_feature_list.index('temp_1'), original_feature_list.index('average')]\n",
        "train_important = original_train_features[:, important_indices]\n",
        "test_important = original_test_features[:, important_indices]\n",
        "\n",
        "# Train the random forest\n",
        "rf_most_important.fit(train_important, original_train_labels)\n",
        "\n",
        "# Make predictions and determine the error\n",
        "predictions = rf_most_important.predict(test_important)\n",
        "\n",
        "errors = abs(predictions - original_test_labels)\n",
        "\n",
        "# Display the performance metrics\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "\n",
        "r2_score(predictions, original_test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 3.92 degrees.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7153950859886571"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSt7rIY8k3DJ"
      },
      "source": [
        "# **Gradient Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njlq3MibzGxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7d5216-1b1f-4841-e02d-0b6ae6abef87"
      },
      "source": [
        "x_train = original_train_features\n",
        "y_train = original_train_labels\n",
        "x_test = original_test_features\n",
        "y_test = original_test_labels\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2016. ,    9. ,   19. , ...,   68. ,   69. ,   69.7],\n",
              "       [2016. ,    4. ,   14. , ...,   60. ,   59. ,   58.1],\n",
              "       [2016. ,    7. ,   30. , ...,   85. ,   88. ,   77.3],\n",
              "       ...,\n",
              "       [2016. ,    4. ,   19. , ...,   77. ,   89. ,   59. ],\n",
              "       [2016. ,   10. ,   14. , ...,   66. ,   60. ,   60.2],\n",
              "       [2016. ,    4. ,   15. , ...,   59. ,   59. ,   58.3]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCPCO2F5ywry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f26d0d-60a6-4b4b-ca84-30ac8b814edc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(max_depth = 3, n_estimators = 100)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8334768428482985"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xadPnWPuk5aT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b109605-4651-4261-91fc-61d43a0e1698"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "for lr in [0.01,0.05,0.1,0.3,0.5,0.8,1]:\n",
        "  model= GradientBoostingRegressor(learning_rate=lr)\n",
        "  model.fit(x_train, y_train)\n",
        "  print(\"Learning rate : \", lr, \" Train score : \", model.score(x_train,y_train), \" Test score : \", model.score(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate :  0.01  Train score :  0.7484522480903714  Test score :  0.698802325257024\n",
            "Learning rate :  0.05  Train score :  0.9356856156545367  Test score :  0.818636932652071\n",
            "Learning rate :  0.1  Train score :  0.9617152359007575  Test score :  0.8207209227948594\n",
            "Learning rate :  0.3  Train score :  0.9953887685512474  Test score :  0.790211955047369\n",
            "Learning rate :  0.5  Train score :  0.9994011646472365  Test score :  0.792324880444135\n",
            "Learning rate :  0.8  Train score :  0.9999390420498501  Test score :  0.689455041926394\n",
            "Learning rate :  1  Train score :  0.9999819420622645  Test score :  0.6738564671898306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69TgRljQwpwj"
      },
      "source": [
        "# XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Vf_NLJYSWXH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvg6zsMFii6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730b21f5-163b-4be8-839a-5f4f17b24886"
      },
      "source": [
        "import xgboost as xgb            # xgboost : separate package\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "for lr in [0.01,0.02,0.03,0.04,0.05,0.1,0.11,0.12,0.13,0.14,0.15,0.2,0.5,0.7,1]:\n",
        "  model = xgb.XGBRegressor(learning_rate = lr, n_estimators=100, verbosity = 0) # learing rate = lambda   # XGBClassifier for classification \n",
        "                                                                                # verbosity=0 means dont show warnings\n",
        "  model.fit(x_train,y_train) #train the model\n",
        "  model.score(x_test, y_test) # scoring the model - r2 squared\n",
        "  print(\"Learning rate : \", lr, \" Train score : \", model.score(x_train,y_train), \" Cross-Val score : \", np.mean(cross_val_score(model, x_train, y_train, cv=10)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate :  0.01  Train score :  -3.0966307094653214  Cross-Val score :  -3.569700426074859\n",
            "Learning rate :  0.02  Train score :  0.33131544261880264  Cross-Val score :  0.2339338272968227\n",
            "Learning rate :  0.03  Train score :  0.8202636422492008  Cross-Val score :  0.7389207908481328\n",
            "Learning rate :  0.04  Train score :  0.8988320111357805  Cross-Val score :  0.7988688480953361\n",
            "Learning rate :  0.05  Train score :  0.9176092305406434  Cross-Val score :  0.8030686887502352\n",
            "Learning rate :  0.1  Train score :  0.9513613662409698  Cross-Val score :  0.7973137545903091\n",
            "Learning rate :  0.11  Train score :  0.94963606511587  Cross-Val score :  0.7964313719566852\n",
            "Learning rate :  0.12  Train score :  0.9539757371063486  Cross-Val score :  0.7880759244741162\n",
            "Learning rate :  0.13  Train score :  0.9589192897797719  Cross-Val score :  0.7895478935317866\n",
            "Learning rate :  0.14  Train score :  0.9614778759930681  Cross-Val score :  0.7852648723722655\n",
            "Learning rate :  0.15  Train score :  0.9657869946687095  Cross-Val score :  0.7772762048681938\n",
            "Learning rate :  0.2  Train score :  0.9783846797709735  Cross-Val score :  0.7681320798445964\n",
            "Learning rate :  0.5  Train score :  0.9974369561968838  Cross-Val score :  0.7467686601016608\n",
            "Learning rate :  0.7  Train score :  0.9992991001148047  Cross-Val score :  0.6993114475988066\n",
            "Learning rate :  1  Train score :  0.9998201373276872  Cross-Val score :  0.6422593468244223\n"
          ]
        }
      ]
    }
  ]
}